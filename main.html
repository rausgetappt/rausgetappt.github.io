<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Diskriminierende Algorithmen</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <script src="script.js"></script>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <script src="https://kit.fontawesome.com/d47d6502d0.js" crossorigin="anonymous"></script>
            <style>
                a { color: rgb(0, 0, 0); } 
            </style>             
    </head>
    
    <body>
        <div class="container">
        <nav class="Navi-leiste">
            <li><a href="#erster"> 1. Abschnitt</a></li>
            <li><a href="#zweiter"> 2. Abschnitt</a></li>
            <li><a href="#dritter"> 3. Abschnitt</a></li>
            <li><a href="#vierter"> 4. Abschnitt</a></li>
            <li><a href="#funfter"> 5. Abschnitt</a></li>
            <li><a href="#sechster"> 6. Abschnitt</a></li>
            <li><a href="#siebter"> 7. Abschnitt</a></li>
            <li><a href="#achter"> 8. Abschnitt</a></li>
            <li><a href="#unserteam"> Kontakt</a></li>

        </nav>
        
    </div>  

        </div>

        <section id="home">
            <div class="content">
                <h1>Diskriminierende Algorithmen und ihre Gefahren f&uuml;r die Gesellschaft</h1>
                <img src="Grafiken/Pfeilunten.png" width="50" height="auto">
        </section>
        
        <section id="erster">
            <div class="erster">
            <h1>Einleitung</h1> 
                <p>Das Thema Algorithmen ist kein Thema von morgen, es ist pr&auml;senter als nie zu vor. Die k&uuml;nstliche Intelligenz nimmt Menschen Entscheidungen ab, die &uuml;ber die berufliche Karriere oder &uuml;ber einer Kreditvergabe von einer Person entscheidet. Dadurch kann man zum Beispiel seinen Traumjob nicht bekommen, oder sein gew&uuml;nschtes Eigenheim nicht finanzieren. Es besteht keine Frage, dass k&uuml;nstliche Intelligenz wichtig ist und sie auch gef&ouml;rdert werden sollte, schliesslich kann sie jetzt schon viele Aufgaben wie zum Beispiel Autofahren, Operationen vollf&uuml;hren oder Schach spielen besser als jeder Mensch. Aber auch k&uuml;nstliche Intelligenz birgt viele Gefahren, so ist die KI nur so gut wie die Erschaffer:innen und &uuml;bernimmt Sexismus, Rassismus und Schubladendenken.</p>   
            </div>    
            </section>
        <section id="zweiter">
            <div class="zweiter">
            <h1>Was sind diskriminiernde Algorithmen?</h1>
                <p>Ein Algorithmus ist ein Programm, das vielen klar definierten Schritten folgt und daraus ein Ergebnis errechnet. Dabei wird das Programm mit Unmengen an Daten gef&uuml;ttert, um basierend auf diesen Daten eine Entscheidung zu treffen.
                    Das hei&szlig;t dass zum Beispiel bei einer Kreditvergabe die KI anhand von Faktoren wie dem Gehalt und der Verl&auml;sslichkeit bei der Zur&uuml;ckzahlung von Krediten errechnet wer einen Kredit bekommt. Jedoch kommen auch andere, vollkommen irrelevante Daten wie beispielsweise die Hautfarbe oder Religion hinzu, aus denen die Kreditvergabe errechnet wird.
                    Systeme, die solche irrelevanten Daten zum Errechnen eines Ergebnisses nutzen sind nicht nur unfair, sondern verst&auml;rken auch Vorurteile in der Gesellschaft.</p>
            </div>
            </section>

        <section id="dritter">
            <div class="dritter">
            <h1>Diskriminierende Algorithmen in der Justiz</h1>
            <div id="dritter">
                <p>
                    In Florida wird f&uuml;r jede Gerichtsverhandlung die Software &quot;Compas&quot; (Correctional Offender Management Profiling for Alternative Sanctions) eingesetzt, die &uuml;ber die Strafe der Angeklagten entscheidet. Ebenso kann der Algorithmus ein Hilfsmittel sein, um beispielsweise die R&uuml;ckf&auml;lligkeit der Angeklagten zu berechnen. Diese Algorithmen w&uuml;rde bei derselben Straftat zweier Personen ein unterschiedliches gerichtliches Urteil treffen. Diese Entscheidungen f&auml;llt das Programm auf der Basis von Hautfarbe, Religion und dem Geschlecht der Angeklagten Personen. Meist greift dieses Programm auf Schubladendenken zur&uuml;ck und hat nichts mit einer objektiven Entscheidung zu tun. Ebenso hat dieses Programm eine fragw&uuml;rdige Erfolgsquote, die die Kompetenz des Programms infrage stellt. Der Algorithmus hat lediglich eine Erfolgsquote von 20% beim hervorsagen der R&uuml;ckf&auml;lligkeit der Verurteilten Menschen. Bei Schwarzen ist die Wahrscheinlichkeit fast doppelt so hoch wie bei Wei&szlig;en, dass sie als risikoreicher eingestuft werden, aber tats&auml;chlich nicht wieder straff&auml;llig werden. Bei Wei&szlig;en passiert genau das Gegenteil: Bei ihnen ist es viel wahrscheinlicher als bei Schwarzen, dass sie als risiko&auml;rmer eingestuft werden, dann aber andere Straftaten begehen. 
                </p>
        </section>
            
        <section id="vierter">
            <div class="vierter">
            <h1>Diskriminierende Algorithmen in Unternehmen</h1>
                <p> Wie bereits erkl&auml;rt, braucht eine KI viele Daten um Zusammenh&auml;nge und Muster zu erlernen. Deswegen werden viele historische Daten verwendet, um die KI mit den unmengen an Daten zu f&uuml;ttern.
                    Dabei sind historische Daten meist kontraproduktiv. Denn historische Daten haben offensichtlich keinen Aktualit&auml;tsbezug, deswegen stellt es die veralteten historischen Strukturen da. Ebenso stellt es die gesellschaftlichen ungerechten Verh&auml;ltnisse dar, wie zum Beispiel zwischen Mann und Frau.
                    Diesen Fehler hat auch das milliarden schwere Unternehmen Amazon gemacht. So wollte das Unternehmen einen Algorithmus programmieren, um automatisiert Mitarbeiter:inenn einzustellen. Bei der Programmierung des Algorithmus wurden historische Daten von ehemals guten Angestellten benutzt, die angestellt waren. Anhand dieser Daten ist der Algorithmus auf das Ergebnis gekommen, dass nur wei&szlig;e M&auml;nner in der Zukunft angestellt werden sollen. Amazon bestreitet bis heute immer wieder die Sachlage, obwohl immer wieder neue Studien das Gegenteil belegen.
                    <br> Weitere Unternehmen die bewiesenerma&szlig;en Algorithmen nutzen, die Menschengruppen benachteiligen, sind:
                    
                    <br> <br> <br></p>

                        <table class="Tabelle">
                            <tr>
                                <th>Firmen</th>
                                <th>Diskriminierung</th>
                            </tr>
                            <tr>
                                <td>Microsoft</td> 
                                <td>Facebook (Sexistische Auswahl, wer welche Anzeigen geschaltet bekommt)</td>                   
                            </tr>
                            <tr>
                                <td>Amazon</td>
                                <td>Bewerber (Automatisierte Ablehnung von Bewerbungen von Frauen und Schwarzen)</td>
                            </tr>
                            <tr>
                                <td>Apple</td>
                                <td>Kredit (Frauen wurden automatisch als Kreditunw&uuml;rdiger eingestuft)</td>
                            </tr>
                        </table>               
                    </div>
           </div>
        </section>
        
        <section id="funfter">
            <div class="funfter">
            <h1>Gesellschaftlichen Wertvorstellungen beim Entwickeln von Algorithmen</h1>
                <p>Die &quot;Gesellschaftlichen Wertvorstellungen&quot; ist ein Ausdruck mit viel Bedeutung und vielen verschiedenen Perspektiven. Dieses Thema schafft deswegen bei Algorithmen auch meistens gro&szlig;e Probleme. Man muss aber aufpassen beim Suchen nach dem Schuldigen, denn meistens k&ouml;nnen die Entwickler:innen gar nichts f&uuml;r solche Fehler. Denn aufgrund fehlender Kompetenz kann es in dem Bereich zu Fehlern kommen. <br> Ebenso fehlt oft Diversit&auml;t im Entwicklungsteam. Ein Resultat eines solchen Fehlers sieht man sehr h&auml;ufig bei der Flugzeugkontrolle. Dort m&uuml;ssen sich Transgender zum Beispiel oft einer intimen und unangenehmen Untersuchung unterziehen. Sowas passiert nur deswegen, weil das System diese Menschen als gef&auml;hrlich einsch&auml;tzt. Dieser Fehler passiert nur auf Grund dessen, dass das System nur m&auml;nnlich und weiblich eingetragen hat. Man kann sich vorstellen, dass eine nicht-bin&auml;re Person oder eine Fortbildung geholfen h&auml;tte, dieses Problem nicht aufkommen zu lassen.</p>
                
            </div>
        </section>
 
        <section id="sechster">
            <div class="sechster">
            <h1>Die Undurchsichtigkeit der modernen Algorithmen</h1>
                <p>Die heutzutage existierenden Algorithmen sind so komplex und verstrickt, dass die echte Verarbeitung der Daten gar nicht mehr sichtbar ist. Selbst f&uuml;r die Entwickler ist im Nachhinein nicht mehr sichtbar welche Schritte die KI geht, um an ihr Endergebnis zu kommen. Deswegen ist es im Nachhinein unm&ouml;glich diskriminierende Strukturen im Programm zu &uuml;ndern, geschweige denn sie zu ver&auml;ndern.</p>

            </div>
        </section>

        <section id="siebter">
            <div class="siebter">  
            <h1>Sexismus im Fallbeispiel Google-&Uuml;bersetzer</h1>
                <p>Die Fehler die Algorithmen machen, sind die selben wie wir sie im Alltag erleben. Die KIs sind wie ein Spiegel unserer Gesellschaft. <br> So l&auml;sst sich beispielsweise das Thema Sexismus ist nicht nur im allt&auml;glichen Leben, sondern auch auf &Uuml;bersetzungsplattformen zu finden.</p>
                <img src="Grafiken/google1.PNG" alt="Beispiel">
            </div>
        </section>
        
        
        
        <section id="achter">
            <div class="achter">
                <h1>Verbesserung und L&ouml;sungsans&auml;tze</h1>
                    <p>Die Gleichberechtigung aller Menschen muss auch ein Thema in Entwicklerteams werden. Ebenso sinnvoll sind ethische Richtlinien oder Gesetzte f&uuml;r KIs, wie zum Beispiel menschliche &Uuml;berpr&uuml;fungen der Ergebnisse, die die KI errechnet.
                        Ebenso ist es wichtig Entwicklungsteams zu Schulen, damit sie &uuml;berhaupt erst die Probleme verstehen k&ouml;nnen und sie dadurch verhindern k&ouml;nnen. Der Schwerpunkt sollte da auf Ungerechtigkeit und Diskriminierung liegen. 
                        Ein anderer Punkt ist das die Entwicklungsteams mehr Diversit&auml;t brauchen. Wenn man ein funktionierendes und faires System aufbauen m&ouml;chte, dann sollte man auch alle Sichten auf der Entscheidungsfindung vereinen.                        
                        Ebenso braucht es Anlaufstellen f&uuml;r Betroffene, damit sie &uuml;berhaupt merken, dass sie diskriminiert werden. Ebenso sollte man dort Hilfe f&uuml;r Betroffene anbieten.
                        Es gibt viele L&ouml;sungswege f&uuml;r Unternehmen, die Benachteiligung bestimmter Menschen verhindern, jedoch steht oftmals der Profit im Vordergrund. </p>
            </div>
        </section>




        <section id="unserteam">
                <h1>Unser Team</h1>
            <p>Kontaktieren Sie uns hier per E-Mail</p>
        <div > 
            <img src="Grafiken/Timo.png" alt="1" usemap="#eins">
                <map name="eins">
                    <area shape="rect" coords="0,203,131,236" alt="Name" href="mailto:timmal@gymnasium-alleestrasse.de">
                </map>

            <img src="Grafiken/Tarik.png" alt="2" usemap="#zwei">
                <map name="zwei">
                    <area shape="rect" coords="130,205,279,235" alt="Name" href="mailto:tarwie@gymnasium-alleestrasse.de">
                </map>

            <img src="Grafiken/Artur.png" alt="3" usemap="#drei">
                <map name="drei">
                    <area shape="rect" coords="193,210,319,233" alt="Name" href="mailto:artwel@gymnasium-alleestrasse.de">
                </map>

            <img src="Grafiken/Noel.png" alt="4" usemap="#vier">
                <map name="vier">
                    <area shape="rect" coords="250,210,393,230" alt="Name" href="mailto:noebec@gymnasium-alleestrasse.de">
                
             
                </map>
        </div> 

        <a class="HochScrollKnopf" href="#"><i class="fa-solid fa-angles-up"></i></a>

    </body>
</html>
